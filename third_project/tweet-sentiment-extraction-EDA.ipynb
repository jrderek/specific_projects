{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:57.718572Z",
     "iopub.status.busy": "2020-09-16T08:06:57.717887Z",
     "iopub.status.idle": "2020-09-16T08:06:57.819134Z",
     "shell.execute_reply": "2020-09-16T08:06:57.817943Z"
    },
    "papermill": {
     "duration": 0.13005,
     "end_time": "2020-09-16T08:06:57.819265",
     "exception": false,
     "start_time": "2020-09-16T08:06:57.689215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing data sets\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('Fix_The_Country_Train_data.csv')\n",
    "test_data = pd.read_csv('Fix_The_Country_Test_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:57.879738Z",
     "iopub.status.busy": "2020-09-16T08:06:57.879043Z",
     "iopub.status.idle": "2020-09-16T08:06:57.907650Z",
     "shell.execute_reply": "2020-09-16T08:06:57.908193Z"
    },
    "papermill": {
     "duration": 0.066785,
     "end_time": "2020-09-16T08:06:57.908315",
     "exception": false,
     "start_time": "2020-09-16T08:06:57.841530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training data details\n",
    "train_data.info()\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:57.976323Z",
     "iopub.status.busy": "2020-09-16T08:06:57.975316Z",
     "iopub.status.idle": "2020-09-16T08:06:57.980880Z",
     "shell.execute_reply": "2020-09-16T08:06:57.981439Z"
    },
    "papermill": {
     "duration": 0.048375,
     "end_time": "2020-09-16T08:06:57.981587",
     "exception": false,
     "start_time": "2020-09-16T08:06:57.933212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing data details\n",
    "test_data.info()\n",
    "test_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025572,
     "end_time": "2020-09-16T08:06:58.033236",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.007664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this competition, the aim is to identify/extract \"selected_text\" from the \"text\" field of the test data set. Only after that, we will be able to cross-check and verify whether sentiment extracted in \"sentiment\" column of the test data set is correct or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:58.103280Z",
     "iopub.status.busy": "2020-09-16T08:06:58.102301Z",
     "iopub.status.idle": "2020-09-16T08:06:58.120205Z",
     "shell.execute_reply": "2020-09-16T08:06:58.120934Z"
    },
    "papermill": {
     "duration": 0.061742,
     "end_time": "2020-09-16T08:06:58.121064",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.059322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Row counts where missing value is present in Train data\n",
    "print(train_data.notnull().sum())\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026256,
     "end_time": "2020-09-16T08:06:58.176307",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.150051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is one row in the training data set which has its \"text\" and \"selected text\" missing. We can discard that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:58.245363Z",
     "iopub.status.busy": "2020-09-16T08:06:58.244328Z",
     "iopub.status.idle": "2020-09-16T08:06:58.250679Z",
     "shell.execute_reply": "2020-09-16T08:06:58.251299Z"
    },
    "papermill": {
     "duration": 0.04854,
     "end_time": "2020-09-16T08:06:58.251424",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.202884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.dropna(axis = 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:58.311110Z",
     "iopub.status.busy": "2020-09-16T08:06:58.310197Z",
     "iopub.status.idle": "2020-09-16T08:06:58.314449Z",
     "shell.execute_reply": "2020-09-16T08:06:58.315211Z"
    },
    "papermill": {
     "duration": 0.039115,
     "end_time": "2020-09-16T08:06:58.315395",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.276280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Row counts where missing value is present in Test data\n",
    "print(test_data.notnull().sum())\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:58.381659Z",
     "iopub.status.busy": "2020-09-16T08:06:58.380719Z",
     "iopub.status.idle": "2020-09-16T08:06:58.580517Z",
     "shell.execute_reply": "2020-09-16T08:06:58.581189Z"
    },
    "papermill": {
     "duration": 0.239818,
     "end_time": "2020-09-16T08:06:58.581334",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.341516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot frequency of positive, negative and neutral sentiments in Train Data\n",
    "from matplotlib import pyplot as plt\n",
    "count_sentiments = pd.value_counts(train_data['Sentiment'], sort=True)\n",
    "count_sentiments.plot(kind='bar', color=(['green','red','orange']), alpha=0.8, rot=0)\n",
    "plt.title(\"Distribution of Sentiment Types in Train Data\")\n",
    "plt.xticks(range(3), ['Positive', 'Negative', 'Neutral'])\n",
    "plt.xlabel(\"Sentiment Type\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:58.707384Z",
     "iopub.status.busy": "2020-09-16T08:06:58.706111Z",
     "iopub.status.idle": "2020-09-16T08:06:58.839622Z",
     "shell.execute_reply": "2020-09-16T08:06:58.839071Z"
    },
    "papermill": {
     "duration": 0.229624,
     "end_time": "2020-09-16T08:06:58.839741",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.610117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot frequency of positive, negative and neutral sentiments in Test Data\n",
    "from matplotlib import pyplot as plt\n",
    "count_sentiments_te = pd.value_counts(test_data['Sentiment'], sort=True)\n",
    "count_sentiments_te.plot(kind='bar', color=(['green','red','orange']), alpha=0.8, rot=0)\n",
    "plt.title(\"Distribution of Sentiment Types in Test Data\")\n",
    "plt.xticks(range(3), ['positive', 'negative', 'neutral'])\n",
    "plt.xlabel(\"Sentiment Type\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027203,
     "end_time": "2020-09-16T08:06:58.896831",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.869628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In both train and test datasets, no. of positive tweets are higher than no. of negative and neutral tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:58.966139Z",
     "iopub.status.busy": "2020-09-16T08:06:58.965277Z",
     "iopub.status.idle": "2020-09-16T08:06:59.192859Z",
     "shell.execute_reply": "2020-09-16T08:06:59.193396Z"
    },
    "papermill": {
     "duration": 0.268745,
     "end_time": "2020-09-16T08:06:59.193560",
     "exception": false,
     "start_time": "2020-09-16T08:06:58.924815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removes punctuation from text. Convert entire text to lower case.\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "train_data['s_text_clean'] = train_data['content'].apply(str).apply(lambda x: remove_punctuation(x.lower()))\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:06:59.256941Z",
     "iopub.status.busy": "2020-09-16T08:06:59.256149Z",
     "iopub.status.idle": "2020-09-16T08:07:00.724406Z",
     "shell.execute_reply": "2020-09-16T08:07:00.723890Z"
    },
    "papermill": {
     "duration": 1.502814,
     "end_time": "2020-09-16T08:07:00.724559",
     "exception": false,
     "start_time": "2020-09-16T08:06:59.221745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Breaks up entire string into a list of words based on a pattern specified by the Regular Expression\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')  \n",
    "train_data['s_text_tokens'] = train_data['s_text_clean'].apply(str).apply(lambda x: tokenizer.tokenize(x))\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:00.791228Z",
     "iopub.status.busy": "2020-09-16T08:07:00.790326Z",
     "iopub.status.idle": "2020-09-16T08:07:30.437566Z",
     "shell.execute_reply": "2020-09-16T08:07:30.437027Z"
    },
    "papermill": {
     "duration": 29.683556,
     "end_time": "2020-09-16T08:07:30.437687",
     "exception": false,
     "start_time": "2020-09-16T08:07:00.754131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if (w not in stopwords.words('english') or w not in 'im')]\n",
    "    return words\n",
    "\n",
    "train_data['s_text_tokens_NOTstop'] = train_data['s_text_tokens'].apply(lambda x: remove_stopwords(x))\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:30.506888Z",
     "iopub.status.busy": "2020-09-16T08:07:30.506244Z",
     "iopub.status.idle": "2020-09-16T08:07:34.088301Z",
     "shell.execute_reply": "2020-09-16T08:07:34.088813Z"
    },
    "papermill": {
     "duration": 3.618184,
     "end_time": "2020-09-16T08:07:34.088946",
     "exception": false,
     "start_time": "2020-09-16T08:07:30.470762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "train_data['s_text_lemma'] = train_data['s_text_tokens_NOTstop'].apply(lambda x: word_lemmatizer(x))\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:34.174215Z",
     "iopub.status.busy": "2020-09-16T08:07:34.169043Z",
     "iopub.status.idle": "2020-09-16T08:07:40.176753Z",
     "shell.execute_reply": "2020-09-16T08:07:40.177236Z"
    },
    "papermill": {
     "duration": 6.056957,
     "end_time": "2020-09-16T08:07:40.177366",
     "exception": false,
     "start_time": "2020-09-16T08:07:34.120409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text\n",
    "\n",
    "train_data['s_text_stem'] = train_data['s_text_lemma'].apply(lambda x: word_stemmer(x))\n",
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:54.520626Z",
     "iopub.status.busy": "2020-09-16T08:07:54.519797Z",
     "iopub.status.idle": "2020-09-16T08:07:55.763870Z",
     "shell.execute_reply": "2020-09-16T08:07:55.764462Z"
    },
    "papermill": {
     "duration": 1.298682,
     "end_time": "2020-09-16T08:07:55.764632",
     "exception": false,
     "start_time": "2020-09-16T08:07:54.465950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def unique_words_analysis(df):\n",
    "    fig,ax = plt.subplots(1,3, figsize=(16,4))\n",
    "    for i,s in enumerate(sentiment):\n",
    "        new = train_data[train_data['Sentiment']==s]['s_text_stem'].map(lambda x: len(set(x.split())))\n",
    "        if (s =='Positive'):\n",
    "            sns.distplot(new.values, ax = ax[i], color='green', rug=True)\n",
    "        if (s =='Neutral'):\n",
    "            sns.distplot(new.values, ax = ax[i], color='orange', rug=True)\n",
    "        if (s =='Negative'):\n",
    "            sns.distplot(new.values, ax = ax[i], color='red', rug=True)\n",
    "        ax[i].set_title(s)\n",
    "    fig.suptitle('Distribution of number of unique words')\n",
    "    fig.show()\n",
    "\n",
    "unique_words_analysis(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047472,
     "end_time": "2020-09-16T08:07:55.860822",
     "exception": false,
     "start_time": "2020-09-16T08:07:55.813350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We observe that both positive and negative tweets' no. of unique words follow almost the similar pattern of distribution (positively skewed). Though neutral tweets also follow a positively skewed distribution, it has a more wide spread as compared to the spread of other two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:55.964817Z",
     "iopub.status.busy": "2020-09-16T08:07:55.963797Z",
     "iopub.status.idle": "2020-09-16T08:07:55.984262Z",
     "shell.execute_reply": "2020-09-16T08:07:55.983686Z"
    },
    "papermill": {
     "duration": 0.076802,
     "end_time": "2020-09-16T08:07:55.984385",
     "exception": false,
     "start_time": "2020-09-16T08:07:55.907583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Segregating positive, negative, neutral sentiment data\n",
    "positive_train = train_data[train_data['Sentiment']=='Positive']\n",
    "neutral_train = train_data[train_data['Sentiment']=='Neutral']\n",
    "negative_train = train_data[train_data['Sentiment']=='Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:56.103444Z",
     "iopub.status.busy": "2020-09-16T08:07:56.102421Z",
     "iopub.status.idle": "2020-09-16T08:07:57.905115Z",
     "shell.execute_reply": "2020-09-16T08:07:57.906435Z"
    },
    "papermill": {
     "duration": 1.874872,
     "end_time": "2020-09-16T08:07:57.906702",
     "exception": false,
     "start_time": "2020-09-16T08:07:56.031830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common Word frequency analysis for positive text\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "fdist_pos = FreqDist(positive_train['s_text_stem'])\n",
    "top_twen_pos = fdist_pos.most_common(20)\n",
    "#top_ten_pos\n",
    "\n",
    "df1 = pd.DataFrame(top_twen_pos, columns = ['Text' , 'count'])\n",
    "df1.groupby('Text').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', color='green', linecolor='black', title='Top 20 Common Words in positive text',orientation='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:58.092833Z",
     "iopub.status.busy": "2020-09-16T08:07:58.091810Z",
     "iopub.status.idle": "2020-09-16T08:07:58.203032Z",
     "shell.execute_reply": "2020-09-16T08:07:58.204188Z"
    },
    "papermill": {
     "duration": 0.207726,
     "end_time": "2020-09-16T08:07:58.204390",
     "exception": false,
     "start_time": "2020-09-16T08:07:57.996664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common Word frequency analysis for neutral text\n",
    "\n",
    "fdist_neu = FreqDist(neutral_train['s_text_stem'])\n",
    "top_twen_neu = fdist_neu.most_common(20)\n",
    "\n",
    "df2 = pd.DataFrame(top_twen_neu, columns = ['Text' , 'count'])\n",
    "df2.groupby('Text').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', color='orange', linecolor='black', title='Top 20 Common Words in neutral text',orientation='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-16T08:07:58.433272Z",
     "iopub.status.busy": "2020-09-16T08:07:58.432370Z",
     "iopub.status.idle": "2020-09-16T08:07:58.566255Z",
     "shell.execute_reply": "2020-09-16T08:07:58.567573Z"
    },
    "papermill": {
     "duration": 0.257492,
     "end_time": "2020-09-16T08:07:58.567783",
     "exception": false,
     "start_time": "2020-09-16T08:07:58.310291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common Word frequency analysis for negative text\n",
    "\n",
    "fdist_neg = FreqDist(negative_train['s_text_stem'])\n",
    "top_twen_neg = fdist_neg.most_common(20)\n",
    "\n",
    "df3 = pd.DataFrame(top_twen_neg, columns = ['Text' , 'count'])\n",
    "df3.groupby('Text').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', color='red', linecolor='black', title='Top 20 Common Words in negative text',orientation='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.104641,
     "end_time": "2020-09-16T08:07:58.763345",
     "exception": false,
     "start_time": "2020-09-16T08:07:58.658704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Exploratory data analysis ends here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.275381,
     "end_time": "2020-09-16T08:10:59.294677",
     "exception": false,
     "start_time": "2020-09-16T08:10:59.019296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "papermill": {
   "duration": 247.949726,
   "end_time": "2020-09-16T08:11:01.397763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-16T08:06:53.448037",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
